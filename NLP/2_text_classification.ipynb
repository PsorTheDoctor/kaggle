{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_text_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMTCR5e+Q8C2yLygAY4uYUy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PsorTheDoctor/kaggle/blob/master/NLP/2_text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npM8QlgMOUl6",
        "colab_type": "text"
      },
      "source": [
        "# Klasyfikacja tekstu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7bgwfWtC7fM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "cfc36310-804a-4e41-a624-5b3534732541"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Załadowanie danych\n",
        "# ham to etykieta dla wiadomości, które nie są spamem\n",
        "spam = pd.read_csv('spam.csv')\n",
        "spam.head(10)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>spam</td>\n",
              "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ham</td>\n",
              "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>spam</td>\n",
              "      <td>WINNER!! As a valued network customer you have...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>spam</td>\n",
              "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label                                               text\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
              "5  spam  FreeMsg Hey there darling it's been 3 week's n...\n",
              "6   ham  Even my brother is not like to speak with me. ...\n",
              "7   ham  As per your request 'Melle Melle (Oru Minnamin...\n",
              "8  spam  WINNER!! As a valued network customer you have...\n",
              "9  spam  Had your mobile 11 months or more? U R entitle..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQk6VOrsEMoG",
        "colab_type": "text"
      },
      "source": [
        "### Budowanie modelu Bag of Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmXFkxFODQY3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "\n",
        "# Stworzenie pustego modelu\n",
        "nlp = spacy.blank('en')\n",
        "\n",
        "# Stworzenie klasyfikatora tekstu z wyłącznymi klasami i architekturą \"bow\"\n",
        "textcat = nlp.create_pipe(\n",
        "    'textcat',\n",
        "    config={\n",
        "        'exclusive_classes': True,\n",
        "        'architecture': 'bow'})\n",
        "\n",
        "# Dodanie klasyfikatora tekstu do pustego modelu\n",
        "nlp.add_pipe(textcat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcJGxJnRF5vH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e72a6ac8-28c9-4fb9-abe5-f0c8081cb5b2"
      },
      "source": [
        "# Dodanie etykiet do klasyfikatora tekstu \n",
        "textcat.add_label('ham')\n",
        "textcat.add_label('spam')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BO646MBGMN7",
        "colab_type": "text"
      },
      "source": [
        "### Trenowanie modelu klasyfikatora tekstu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JsH1ejHGa0v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_texts = spam['text'].values\n",
        "train_labels = [{'cats': {'ham': label == 'ham',\n",
        "                          'spam': label == 'spam'}}\n",
        "                for label in spam['label']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOsQzPuPHvKS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "56df3b89-c05c-47b1-c41c-ae593dd969b5"
      },
      "source": [
        "train_data = list(zip(train_texts, train_labels))\n",
        "train_data[:3]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...',\n",
              "  {'cats': {'ham': True, 'spam': False}}),\n",
              " ('Ok lar... Joking wif u oni...', {'cats': {'ham': True, 'spam': False}}),\n",
              " (\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\",\n",
              "  {'cats': {'ham': False, 'spam': True}})]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMxpt0nQIU1V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from spacy.util import minibatch\n",
        "\n",
        "spacy.util.fix_random_seed(1)\n",
        "optimizer = nlp.begin_training()\n",
        "\n",
        "# Stworzenie generatora wsadów z rozmiarem wsadu (batch size = 8)\n",
        "batches = minibatch(train_data, size=8)\n",
        "# Iteracaja po miniwsadach\n",
        "for batch in batches:\n",
        "  # Każdy wsad jest listą (tekst, etykieta), ale potrzebujemy\n",
        "  # wysłać osobne listy dla tekstów i etykiet do update()\n",
        "  # To jest szybki sposób listy tupli na listy\n",
        "  text, labels = zip(*batch)\n",
        "  nlp.update(text, labels, sgd=optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CY8loE3dKVyc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "7d044e98-2c69-4a00-f699-8c7fa10d3d8b"
      },
      "source": [
        "import random\n",
        "\n",
        "random.seed(1)\n",
        "spacy.util.fix_random_seed(1)\n",
        "optimizer = nlp.begin_training()\n",
        "\n",
        "losses = {}\n",
        "\n",
        "for epoch in range(10):\n",
        "  random.shuffle(train_data)\n",
        "  # Stworzenie generatora wsadów z rozmiarem wsadu = 8\n",
        "  batches = minibatch(train_data, size=8)\n",
        "  # Iteracaja po miniwsadach\n",
        "  for batch in batches:\n",
        "    # Każdy wsad jest listą (tekst, etykieta), ale potrzebujemy\n",
        "    # wysłać osobne listy dla tekstów i etykiet do update()\n",
        "    # To jest szybki sposób listy tupli na listy\n",
        "    text, labels = zip(*batch)\n",
        "    nlp.update(text, labels, sgd=optimizer, losses=losses)\n",
        "  print(losses)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'textcat': 0.29890368430487513}\n",
            "{'textcat': 0.4806387926536857}\n",
            "{'textcat': 0.5982820415381982}\n",
            "{'textcat': 0.672603283121775}\n",
            "{'textcat': 0.7211023606003482}\n",
            "{'textcat': 0.7543036989518874}\n",
            "{'textcat': 0.7799389380317288}\n",
            "{'textcat': 0.7962947575560354}\n",
            "{'textcat': 0.8090532684510547}\n",
            "{'textcat': 0.8178490321991748}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_9s1zpJL8Dx",
        "colab_type": "text"
      },
      "source": [
        "### Tworzenie predykcji"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wDXWcQVMAZV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4e5e22dd-ab1d-437e-e8e2-d7d7f6ae97b4"
      },
      "source": [
        "texts = [\"Are you ready for a tea party????? It's gonna to be wild\",\n",
        "         \"URGENT Reply for this message for GUARANTEED FREE TEA\"]\n",
        "docs = [nlp.tokenizer(text) for text in texts]\n",
        "\n",
        "# Użycie textcata do dostania się do wyników każdego doca\n",
        "textcat = nlp.get_pipe('textcat')\n",
        "scores, _ = textcat.predict(docs)\n",
        "\n",
        "print(scores)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[9.998926e-01 1.073430e-04]\n",
            " [5.668400e-03 9.943316e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSTLS7-zNZPz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c2d0594a-ac0f-4294-c789-a9c99040fc04"
      },
      "source": [
        "# Znalezienie etykiety z najwyższym wynikiem/prawdopodobieństwem ze scores \n",
        "predicted_labels = scores.argmax(axis=1)\n",
        "print([textcat.labels[label] for label in predicted_labels])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ham', 'spam']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRgGJKr5OJGS",
        "colab_type": "text"
      },
      "source": [
        "### Źródło:\n",
        "[https://www.kaggle.com/matleonard/text-classification](https://www.kaggle.com/matleonard/text-classification)"
      ]
    }
  ]
}